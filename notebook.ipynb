{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Landmark Classifier\n",
    "\n",
    "Photo sharing and photo storage services like to have location data for each photo that is uploaded. With the location data, these services can build advanced features, such as automatic suggestion of relevant tags or automatic photo organization, which help provide a compelling user experience. Although a photo’s location can often be obtained by looking at the photo’s metadata, many photos uploaded to these services will not have location metadata available. This can happen when, for example, the camera capturing the picture does not have GPS or if a photo’s metadata is scrubbed due to privacy concerns.\n",
    "\n",
    "If no location metadata for an image is available, one way to infer the location is to detect and classify a discernible landmark in the image. Given the large number of landmarks across the world and the immense volume of images that are uploaded to photo sharing services, using human judgement to classify these landmarks would not be feasible.\n",
    "\n",
    "This notebook classifies 50 landmarks by building models to automatically predict the location of the image based on any landmarks depicted in the image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Table of Content"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the packages\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from utils import models, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define the batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# get the loaders\n",
    "train_loader, val_loader, test_loader, dataset = preprocess.create_loaders(n_batch=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t\tClasses & Indexes\n",
      "0:\tHaleakala National Park\n",
      "1:\tMount Rainier National Park\n",
      "2:\tLjubljana Castle\n"
     ]
    }
   ],
   "source": [
    "# store loaders\n",
    "loaders = {'train': train_loader,\n",
    "           'val':   val_loader,\n",
    "           'test':  test_loader}\n",
    "\n",
    "# get dictionary and descriptions\n",
    "dictionary = preprocess.Dictionary(dataset)\n",
    "\n",
    "# show first three instances\n",
    "dictionary.simple_print(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'image'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpreprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisualize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdictionary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msingle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\landmark_classified\\utils\\preprocess.py:200\u001B[0m, in \u001B[0;36mvisualize\u001B[1;34m(dictionary, loader, single)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# show single image\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m single:\n\u001B[1;32m--> 200\u001B[0m     i, l \u001B[38;5;241m=\u001B[39m \u001B[43mshow_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     plt\u001B[38;5;241m.\u001B[39mtitle(l, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m)\n\u001B[0;32m    202\u001B[0m     plt\u001B[38;5;241m.\u001B[39mgrid(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Desktop\\landmark_classified\\utils\\preprocess.py:188\u001B[0m, in \u001B[0;36mvisualize.<locals>.show_single\u001B[1;34m(image, lbl, index)\u001B[0m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshow_single\u001B[39m(image, lbl, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;66;03m# unnormalize = transforms.Normalize((-MEAN / STD).tolist(), (1.0 / STD).tolist())\u001B[39;00m\n\u001B[0;32m    184\u001B[0m     denorm \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mNormalize(\n\u001B[0;32m    185\u001B[0m         mean\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m-\u001B[39mm \u001B[38;5;241m/\u001B[39m s \u001B[38;5;28;01mfor\u001B[39;00m m, s \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(MEAN, STD)],\n\u001B[0;32m    186\u001B[0m         std\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m s \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m STD]\n\u001B[0;32m    187\u001B[0m     )\n\u001B[1;32m--> 188\u001B[0m     image \u001B[38;5;241m=\u001B[39m (\u001B[43mdenorm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8)\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;66;03m# image = unnormalize(image[index, :])\u001B[39;00m\n\u001B[0;32m    191\u001B[0m     lbl \u001B[38;5;241m=\u001B[39m convert_label(lbl[index])   \u001B[38;5;66;03m# get the label from dictionary\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() got an unexpected keyword argument 'image'"
     ]
    }
   ],
   "source": [
    "preprocess.visualize(dictionary, train_loader, single=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}